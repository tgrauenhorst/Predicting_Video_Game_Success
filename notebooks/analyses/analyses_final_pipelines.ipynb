{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f125647f-034c-4d02-b38d-4d254edf13b8",
   "metadata": {},
   "source": [
    "# Notebook: Final pipelines\n",
    "\n",
    "#### The dataset analyzed includes data from SteamDB and Game_Data.\n",
    "#### The analyses are based on the best models from analyses_nlp_comparison and analyses_nlp_merged_data_1.\n",
    "#### Additional grid searches are conducted to find the best hyperparameters to use in the final pipelines.\n",
    "\n",
    "#### Step 1: Imports and functions\n",
    "#### Step 2: NLP basics\n",
    "#### Step 3: Fit final models and save for use in aim predictions\n",
    "#### Step 4: Function for prediction of aim data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e2732-d47e-425a-9036-10fb75b24e8f",
   "metadata": {},
   "source": [
    "## Step 1: Imports, functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26eee37a-c9ad-4a24-a573-a54505842c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "## Requirements:\n",
    "## Users might need to manually download stopwords:\n",
    "nltk.download('stopwords')\n",
    "## Additionally, en_core_web_sm has to be downloaded manually:\n",
    "# in terminal: python -m spacy download en_core_web_sm\n",
    "#########################################\n",
    "\n",
    "## General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "from collections import Counter\n",
    "import pickle \n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "## Imports for NLP\n",
    "import nltk, re, spacy, string\n",
    "from spacy.lang.en.examples import sentences\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "## Imports for analyses\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import statsmodels\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "## Imports for UI\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "## Imports from analyses_tools (local)\n",
    "sys.path.append('../../')\n",
    "from analyses_tools import oh_encoder, NLPAnalyzer\n",
    "from utilities import URLMerge\n",
    "\n",
    "## Function to filter entries in detected_technologies for engines used\n",
    "\n",
    "def filter_engine_entries(text):\n",
    "    \"\"\"Extract engine information from detected_technologies\"\"\"\n",
    "    # only keep \"Engine\" entries for detected_technologies:\n",
    "    if isinstance(text, str):\n",
    "        entries = text.replace('; ', ', ').replace(\" \", \"\").split(',')\n",
    "        filtered_entries = [entry.replace(\"Engine.\", \"\") for entry in entries if entry.startswith('Engine.')]\n",
    "        cleaned_text = '; '.join(filtered_entries)    \n",
    "        if cleaned_text == \"\":\n",
    "            return \"Unknown\"\n",
    "        else:\n",
    "            return cleaned_text\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "## Function for counting genres\n",
    "\n",
    "def count_genres(genres):\n",
    "    \"\"\"Count number of genres.\"\"\"\n",
    "    if pd.isna(genres) or genres == '':\n",
    "        return 0\n",
    "    return len(genres.split(','))\n",
    "\n",
    "\n",
    "## Function for extracting word count and average length\n",
    "\n",
    "def calculate_description_metrics(description):\n",
    "    \"\"\"Split the description into words and extract word count and average length.\"\"\"\n",
    "    if pd.isna(description):\n",
    "        return 0, 0.0 \n",
    "    ## Split description\n",
    "    words = re.findall(r'\\b\\w+\\b', description)\n",
    "    # Calculate word count\n",
    "    word_count = len(words)\n",
    "    # Calculate average word length\n",
    "    if word_count > 0:\n",
    "        avg_word_length = sum(len(word) for word in words) / word_count\n",
    "    else:\n",
    "        avg_word_length = 0\n",
    "    return word_count, avg_word_length\n",
    "\n",
    "\n",
    "## Function for data preparation\n",
    "\n",
    "def data_preparation(df):\n",
    "    \"\"\"Take a dataframe, prepare it for use in NLP and analyses and return prepared dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df (Dataframe): Original dataframe to be prepared\n",
    "        \n",
    "    Returns:\n",
    "        df (Dataframe): Prepared dataframe\n",
    "        \n",
    "    \"\"\"\n",
    "   \n",
    "    def count_entries(text):\n",
    "        \"\"\"Helper function to count entries in lists\"\"\"\n",
    "        entries = text.split('; ')\n",
    "        return Counter(entries)\n",
    "    def replace_entries(text, other_entries):\n",
    "        \"\"\"Helper function to replace entries in lists\"\"\"\n",
    "        entries = text.split('; ')\n",
    "        replaced_entries = list(set(['Misc' if entry in other_entries else entry for entry in entries]))\n",
    "        return '; '.join(replaced_entries)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    ###############################    \n",
    "    ## Data Cleaning & Recoding\n",
    "    ###############################\n",
    "    \n",
    "    ## drop columns not used in analyses\n",
    "    df.drop(['sid', 'store_promo_url', 'published_meta', 'published_stsp', 'published_hltb',\n",
    "             'published_igdb', 'image', 'current_price', 'discount', 'publisher', 'developer',\n",
    "             'gfq_url', 'gfq_difficulty_comment', 'gfq_rating_comment', 'gfq_length_comment',\n",
    "             'hltb_url', 'meta_url', 'igdb_url', 'Unnamed: 0', 'game', 'steam_url', 'release', \n",
    "             'positive_reviews', 'negative_reviews', \"review_percentage\", 'primary_genre', 'store_genres', \n",
    "             'store_asset_mod_time', \n",
    "             'players_right_now', '24_hour_peak', 'all_time_peak', 'all_time_peak_date'], \n",
    "            axis=1, inplace=True)\n",
    "\n",
    "    ## publish date as timedelta\n",
    "    df[\"published_store\"] = pd.to_datetime(df[\"published_store\"]) - pd.Timestamp(1997, 1, 1)\n",
    "    df[\"published_store\"] = df[\"published_store\"].apply(lambda value: value.days)\n",
    "     \n",
    "    ## missing data 1: If language or voiceover is missing, set to \"One_unknown\"\n",
    "    df.loc[df[\"languages\"].isna(), \"languages\"] = \"Unknown\"\n",
    "    df.loc[df[\"voiceovers\"].isna(), \"voiceovers\"] = \"Unknown\"\n",
    "\n",
    "    ## delete games without English as language:\n",
    "    count_no_en = 0\n",
    "    for x in df.index:\n",
    "        if \"english\" not in df.loc[x,\"languages\"].lower():\n",
    "            count_no_en += 1\n",
    "            df = df.drop(labels=x, axis=0)\n",
    "    print(f\"Games without English language: {count_no_en}\")\n",
    "             \n",
    "    ## use only number of languages and voiceovers\n",
    "    df[\"languages\"] = df[\"languages\"].apply(lambda value: len(value.split(\",\")))\n",
    "    df[\"voiceovers\"] = df[\"voiceovers\"].apply(lambda value: len(value.split(\",\")))\n",
    "      \n",
    "    ## missing data 2: drop columns with more than 75% missing data:\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > df.shape[0]*0.75:\n",
    "            df.drop(col, axis=1, inplace=True) \n",
    "    \n",
    "    ## One-Hot-Encoding\n",
    "\n",
    "    ## Filter entries in detected_technologies\n",
    "    df['engine'] = df['detected_technologies'].apply(filter_engine_entries)\n",
    "    df = df.drop('detected_technologies', axis=1)\n",
    "\n",
    "    ## Extract word count and average length from description\n",
    "    df['description_count'], df['description_length'] = zip(*df['description'].apply(calculate_description_metrics))\n",
    "    \n",
    "    ## Count number of genres\n",
    "    df['genres_count'] = df['genres'].apply(count_genres)\n",
    "       \n",
    "    ## Splitting mutliple entries\n",
    "    ## split strings in genre and platform columns\n",
    "    df['genres'] = df['genres'].apply(lambda x: x.split(','))\n",
    "    df['platforms'] = df['platforms'].apply(lambda x: x.split(','))\n",
    "    \n",
    "    # Count occurences of entries in \"engine\"\n",
    "    entry_counts = df['engine'].apply(count_entries).sum()\n",
    "    # Identify entries with less than 10 occurences\n",
    "    other_entries = {entry for entry, count in entry_counts.items() if count < 50}\n",
    "    # Replace entries\n",
    "    df['engine'] = df['engine'].apply(lambda lst: replace_entries(lst, other_entries))\n",
    "    df['engine'] = df['engine'].apply(lambda x: x.replace('; ', ', ').replace(\" \", \"\").split(','))\n",
    "    \n",
    "    ## replace genres\n",
    "    df['genres'] = df['genres'].apply(lambda genres: list(set(['Indie' if genre == 'Инди' else genre for genre in genres])))\n",
    "    df['genres'] = df['genres'].apply(lambda genres: list(set(['Adventure' if genre == 'Приключенческие игры' else genre for genre in genres])))\n",
    "    \n",
    "    ## One-Hot Encoding\n",
    "    df[\"genres\"] = df[\"genres\"].fillna(\"Unknown\")\n",
    "    df[\"platforms\"] = df[\"platforms\"].fillna(\"Unknown\")\n",
    "    df[\"engine\"] = df[\"engine\"].fillna(\"Unknown\")\n",
    "    df = oh_encoder(df, \"genres\")\n",
    "    df = oh_encoder(df, \"platforms\")\n",
    "    df = oh_encoder(df, \"engine\")\n",
    "   \n",
    "    ## Generate indicators for multi-player games from categories:\n",
    "    df['Multiplayer'] = df['categories'].apply(\n",
    "        lambda x: 1 if x and ('Multi-player' in x or 'Massively_Multiplayer' in x) else 0\n",
    "        )\n",
    "\n",
    "    ## treat some extreme outliers\n",
    "    train_df.loc[train_df[\"hltb_single\"]>100, \"hltb_single\"] = 100\n",
    "    train_df.loc[train_df[\"full_price\"]>20000, \"full_price\"] = 20000\n",
    "\n",
    "    df = df.drop('categories', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def data_preparation_aim(train_df, df, is_datetime=False):\n",
    "    df=df.copy()\n",
    "\n",
    "    list_of_engines = [\"Source\", \"Unknown\", \"MonoGame\", \"AdventureGameStudio\", \n",
    "                \"Unity\", \"CryEngine\", \"Solar2D\", \"KiriKiri\", \n",
    "                \"XNA\", \"FNA\", \"Unreal\", \"Godot\", \n",
    "                \"Construct\", \"Cocos\", \"Adobe_AIR\", \"TyranoBuilder\", \n",
    "                \"Torque\", \"GameGuru\", \"RenPy\", \"OGRE\", \n",
    "                \"RPGMaker\", \"Love2D\", \"GameMaker\", \"Lime_OR_OpenFL\",\n",
    "                \"BlenderGameEngine\"]\n",
    "                \n",
    "    \n",
    "    ## publish date as timedelta\n",
    "    if is_datetime==True:\n",
    "        df[\"published_store\"] = df[\"published_store\"] - pd.Timestamp(1997, 1, 1)\n",
    "    else:   \n",
    "        df[\"published_store\"] = pd.to_datetime(df[\"published_store\"]) - pd.Timestamp(1997, 1, 1)\n",
    "    df[\"published_store\"] = df[\"published_store\"].apply(lambda value: value.days)\n",
    "\n",
    "    ## process engines\n",
    "    game_engines=[]\n",
    "    for entry in df.loc[0,\"engine\"]:\n",
    "        if entry not in list_of_engines:\n",
    "            game_engines.append(\"Misc\")\n",
    "        else:\n",
    "            game_engines.append(entry)\n",
    "    df.loc[0,\"engine\"] = list(set(game_engines))\n",
    "\n",
    "    ## Extract word count and average length from description\n",
    "    df['description_count'], df['description_length'] = zip(*df['description'].apply(calculate_description_metrics))\n",
    "    \n",
    "    ## Count number of genres\n",
    "    df['genres_count'] = df['genres'].apply(count_genres)\n",
    "       \n",
    "    ## Splitting mutliple entries\n",
    "    ## split strings in genre and platform columns\n",
    "    df['genres'] = df['genres'].apply(lambda x: x.split(','))\n",
    "    df['platforms'] = df['platforms'].apply(lambda x: x.split(','))\n",
    "    \n",
    "    ## One-Hot Encoding\n",
    "    df[\"genres\"] = df[\"genres\"].fillna(\"Unknown\")\n",
    "    df[\"platforms\"] = df[\"platforms\"].fillna(\"Unknown\")\n",
    "    df[\"engine\"] = df[\"engine\"].fillna(\"Unknown\")\n",
    "    df = oh_encoder(df, \"genres\")\n",
    "    df = oh_encoder(df, \"platforms\")\n",
    "    df = oh_encoder(df, \"engine\")\n",
    "    \n",
    "    # Ensure same columns in aim_df as in train_df\n",
    "    for col in train_df.columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    df = df[train_df.columns]\n",
    "\n",
    "    ## apply text cleaner\n",
    "    df[\"description_clean_nonum\"] = df[\"description\"].apply(text_cleaner)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def text_cleaner(sentence):\n",
    "    \"\"\"Take a string, clean it for use in vectorization and return cleaned string.\n",
    "    \n",
    "    Args:\n",
    "        sentence (string): Original string to be cleaned\n",
    "        \n",
    "    Returns:\n",
    "        doc_str (string): Cleaned String\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ## counter\n",
    "    global call_count \n",
    "    call_count += 1\n",
    "    if call_count%1000 == 0:\n",
    "        print(call_count)\n",
    "    if sentence is None:\n",
    "        doc_str = \"\"\n",
    "    else:\n",
    "        ## OPTIONAL: delete html tags (tags can be excluded if one wants to limit analyses to ignore this information):\n",
    "        # sentence = re.sub(\"<.*?>\", \"\", sentence)\n",
    "        \n",
    "        ## tokenize and delete pronouns, stopwords and punctuation\n",
    "        doc = nlp(sentence)\n",
    "        clean_doc = [token.lemma_.lower() for token in doc if (token.pos_ !=\"PRON\") and (token.lemma_ not in stopWords) and (token.lemma_ not in punctuations)]\n",
    "        ## rejoin texts\n",
    "        doc_str = \" \".join(clean_doc)\n",
    "        ## deleting points, tabs, spaces and line breaks\n",
    "        doc_str = re.sub(\"[\\s]+\", \" \", doc_str)\n",
    "        ## deleting numbers\n",
    "        doc_str = re.sub(r'\\d+', '', doc_str) \n",
    "    return doc_str\n",
    "\n",
    "\n",
    "## Adjusting display\n",
    "pd.set_option('display.max_rows', 200) # display more rows\n",
    "pd.set_option('display.max_columns', 50) # display more columns\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) # display numbers as decimals\n",
    "\n",
    "## Suppress some warnings \n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e8eda-0f66-4bff-b478-da4292ebdde5",
   "metadata": {},
   "source": [
    "## Step 2: Data preparation and NLP basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432eb81e-4c35-47ff-94ad-0f0125d176aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## skips NLP for train data if pickel with it was saved already to drastically reduce time needed\n",
    "\n",
    "## load language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "## Clean \"description\"\n",
    "stopWords = stopwords.words(\"english\")\n",
    "punctuations = string.punctuation\n",
    "\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_pickle(\"../../data/train_df_nlp.pkl\", compression='bz2')\n",
    "    \n",
    "except:\n",
    "\n",
    "    ## load and prepare data\n",
    "    train_df = pd.read_pickle(\"../../data/df_merge1.pkl\", compression='bz2')\n",
    "    train_df = data_preparation(train_df)\n",
    "    display(train_df.dtypes)\n",
    "    \n",
    "    ## Applying text_cleaner to description\n",
    "    print(\"*\"*50 + \"\\nStarting text cleaner\\n\" + \"*\"*50) \n",
    "    ## Adding a global counter to print in text_cleaner function since it takes a long time\n",
    "    call_count = 0\n",
    "    ## Using text_cleaner\n",
    "    train_df[\"description_clean_nonum\"] = train_df[\"description\"].apply(text_cleaner)\n",
    "    \n",
    "    train_df.to_pickle(\"../../data/train_df_nlp.pkl\", compression='bz2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14de48-3808-4e5d-8567-8766dc2033c5",
   "metadata": {},
   "source": [
    "## Step 3: Fit final models and save for use in aim predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33e2272-a9fe-4d9a-a97f-e37c2557400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## load vocabulary\n",
    "with open(\"../../data/extracted_word_index.pkl\", \"rb\") as handle:\n",
    "    word_index = pickle.load(handle)\n",
    "custom_vocabulary = word_index[1]\n",
    "\n",
    "## load merged data \n",
    "df = pd.read_pickle(\"../../data/train_df_nlp.pkl\", compression='bz2')\n",
    "\n",
    "\n",
    "## Pipelines\n",
    "\n",
    "def final_fitter(df, target_var, custom_vocabulary, poly_degree=2, rf_min_samples_leaf=3):\n",
    "    \n",
    "    df = df.copy()\n",
    "\n",
    "    ## delete missings\n",
    "    df = df.dropna(axis=0, how=\"any\")\n",
    "\n",
    "    ## Reset index\n",
    "    df.reset_index()\n",
    "\n",
    "    features = df.drop(target_var, axis=1)\n",
    "    target = df[target_var]\n",
    "    \n",
    "    # Define the columns_to_scale and other_columns lists using a list comprehension\n",
    "    columns_to_scale = [\n",
    "        col for col in features.columns\n",
    "        if features[col].nunique() > 2 and pd.api.types.is_numeric_dtype(features[col])\n",
    "    ]\n",
    "    \n",
    "    other_columns = [\n",
    "        col for col in features.columns\n",
    "        if col not in columns_to_scale and col != 'description_clean_nonum'\n",
    "    ]\n",
    "\n",
    "    # Pipeline for numeric features\n",
    "    pipeline_num = Pipeline([\n",
    "        ('scaling', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=poly_degree, include_bias=False))\n",
    "    ])\n",
    "    \n",
    "    # Pipeline for text processing\n",
    "    text_transformer = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer(vocabulary=custom_vocabulary, stop_words='english'))\n",
    "    ])\n",
    "\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', pipeline_num, columns_to_scale),\n",
    "            ('text', text_transformer, 'description_clean_nonum'),\n",
    "            ('other', 'passthrough', other_columns)\n",
    "        ])\n",
    "    \n",
    "    # Main Pipeline with RandomForestRegressor\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=100, min_samples_leaf=rf_min_samples_leaf, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    return pipeline.fit(features, target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5244ef31-20b6-4583-88e8-a46e16e26f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## fitting final models with best hyperparameters\n",
    "\n",
    "\n",
    "final_model_owners = final_fitter(df.drop([\"name\", \"developers\", \"publishers\",\n",
    "                                      \"tags\", \"achievements\", \"gfq_rating\", \"description\", \"voiceovers\",\n",
    "                                      \"peak_players\", \"total_reviews\", \"rating\", \"store_uscore\", \n",
    "                                      \"igdb_popularity\"], axis=1), 'stsp_owners', custom_vocabulary, 1, 15)\n",
    "\n",
    "\n",
    "\n",
    "final_model_rating = final_fitter(df.drop([\"name\", \"developers\", \"publishers\",\n",
    "                                      \"tags\", \"achievements\", \"gfq_rating\", \"description\", \"voiceovers\",\n",
    "                                      \"peak_players\", \"total_reviews\", \"store_uscore\", \"stsp_owners\", \n",
    "                                      \"igdb_popularity\"], axis=1), 'rating', custom_vocabulary, 2, 3)\n",
    "\n",
    "\n",
    "\n",
    "final_model_uscore = final_fitter(df.drop([\"name\", \"developers\", \"publishers\",\n",
    "                                      \"tags\", \"achievements\", \"gfq_rating\", \"description\", \"voiceovers\",\n",
    "                                      \"peak_players\", \"total_reviews\", \"rating\", \"stsp_owners\", \n",
    "                                      \"igdb_popularity\"], axis=1), 'store_uscore', custom_vocabulary, 2, 3)\n",
    "\n",
    "models = [final_model_owners, final_model_rating, final_model_uscore]\n",
    "\n",
    "\n",
    "## save models as pickle\n",
    "with gzip.open(\"../../models/final_models.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump(models, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a6b49-da5d-463d-a56e-717e05cb03e8",
   "metadata": {},
   "source": [
    "## Step 4: Function for prediction of aim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e38c41-21da-48ba-bd1b-d3458a08ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "## optional: load models from pickle object\n",
    "# with gzip.open(\"../../models/final_models.pkl.gz\", \"rb\") as f:\n",
    "#     models = pickle.load(f)\n",
    "####################################################################\n",
    "\n",
    "## Function for Predictions: \n",
    "\n",
    "def predictor(models, df_aim):\n",
    "\n",
    "    ## predictions\n",
    "    y_owners = models[0].predict(df_aim)\n",
    "    y_rating = models[1].predict(df_aim)\n",
    "    y_uscore = models[2].predict(df_aim)\n",
    "\n",
    "    return y_owners, y_rating, y_uscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1d1d12-c81e-43e3-bb55-9403828e8ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259198.95163818]\n",
      "[63.74261814]\n",
      "[60.79136183]\n",
      "[2423534.8192595]\n",
      "[74.57429452]\n",
      "[75.12423232]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Testing predictions with examplary data\n",
    "\n",
    "## example data 1\n",
    "data_1 = {'published_store': ['2024-08-01'], \n",
    "          'name': [\"New Game 1\"],     \n",
    "          'description': ['An action game with different enemies you need to play.'],\n",
    "          'full_price': [199],\n",
    "          'languages': [1],\n",
    "          'hltb_single': [2.0],        \n",
    "          'genres': ['Casual'],\n",
    "          'platforms': ['WIN'],\n",
    "          'engine': ['Unity'],\n",
    "          'Multiplayer': [0],\n",
    "          }\n",
    "\n",
    "df_aim = pd.DataFrame.from_dict(data_1)\n",
    "call_count = 0\n",
    "df_aim = data_preparation_aim(df, df_aim)\n",
    "\n",
    "## make predictions\n",
    "y_owners, y_rating, y_uscore = predictor(models, df_aim)\n",
    "\n",
    "for prediction in [y_owners, y_rating, y_uscore]:\n",
    "    print(prediction)\n",
    "\n",
    "## example data 2\n",
    "data_2 = {'published_store': ['2025-08-01'], \n",
    "          'name': [\"New Game 2\"],     \n",
    "          'description': ['''An action game with great graphics and battles. \n",
    "                          You can... \n",
    "                          <ul>\n",
    "                          <li>explore the new world with many new areas,</li>\n",
    "                          <li>find new friends,</li>\n",
    "                          <li>gain new unique powers,</li>\n",
    "                          <li>get strong,</li>\n",
    "                          <li>solve new unique puzzles,</li> \n",
    "                          <li>overcome challenges,</li>\n",
    "                          <li>enjoy adventures,</li>\n",
    "                          <li>live a live,</li>\n",
    "                          <li>find ways to complete the story,</li>\n",
    "                          <li>make things,</li>\n",
    "                          <li>and become a strong and friendly character.</li>\n",
    "                          </ul)\n",
    "                          '''],\n",
    "          'full_price': [4999],\n",
    "          'languages': [12],\n",
    "          'hltb_single': [20.0],        \n",
    "          'genres': ['Action'],\n",
    "          'platforms': ['WIN, LNX, MAC'],\n",
    "          'engine': ['Unreal'],\n",
    "          'Multiplayer': [1],\n",
    "          }\n",
    "\n",
    "df_aim = pd.DataFrame.from_dict(data_2)\n",
    "call_count = 0\n",
    "df_aim = data_preparation_aim(df, df_aim)\n",
    "\n",
    "## make predictions\n",
    "y_owners, y_rating, y_uscore = predictor(models, df_aim)\n",
    "\n",
    "for prediction in [y_owners, y_rating, y_uscore]:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db72d3da-a09a-4081-9414-c366670c86d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>stsp_owners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1443.00</td>\n",
       "      <td>1443.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.37</td>\n",
       "      <td>782176.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.28</td>\n",
       "      <td>2579473.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.02</td>\n",
       "      <td>35000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.06</td>\n",
       "      <td>150000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.23</td>\n",
       "      <td>750000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.32</td>\n",
       "      <td>35000000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_sales  stsp_owners\n",
       "count      1443.00      1443.00\n",
       "mean          0.37    782176.02\n",
       "std           1.28   2579473.29\n",
       "min           0.00     10000.00\n",
       "25%           0.02     35000.00\n",
       "50%           0.06    150000.00\n",
       "75%           0.23    750000.00\n",
       "max          20.32  35000000.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>total_sales</td>   <th>  R-squared (uncentered):</th>      <td>   0.346</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.345</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   762.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 18 Jun 2024</td> <th>  Prob (F-statistic):</th>          <td>4.69e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:01:32</td>     <th>  Log-Likelihood:    </th>          <td> -2158.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1443</td>      <th>  AIC:               </th>          <td>   4318.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1442</td>      <th>  BIC:               </th>          <td>   4324.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stsp_owners</th> <td> 2.913e-07</td> <td> 1.06e-08</td> <td>   27.609</td> <td> 0.000</td> <td> 2.71e-07</td> <td> 3.12e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1648.013</td> <th>  Durbin-Watson:     </th>  <td>   1.169</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>355577.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 5.367</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>79.149</td>  <th>  Cond. No.          </th>  <td>    1.00</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &   total\\_sales   & \\textbf{  R-squared (uncentered):}      &     0.346   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.345   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     762.3   \\\\\n",
       "\\textbf{Date:}             & Tue, 18 Jun 2024 & \\textbf{  Prob (F-statistic):}          & 4.69e-135   \\\\\n",
       "\\textbf{Time:}             &     00:01:32     & \\textbf{  Log-Likelihood:    }          &   -2158.2   \\\\\n",
       "\\textbf{No. Observations:} &        1443      & \\textbf{  AIC:               }          &     4318.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1442      & \\textbf{  BIC:               }          &     4324.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{stsp\\_owners} &    2.913e-07  &     1.06e-08     &    27.609  &         0.000        &     2.71e-07    &     3.12e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1648.013 & \\textbf{  Durbin-Watson:     } &     1.169   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 355577.245  \\\\\n",
       "\\textbf{Skew:}          &   5.367  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &  79.149  & \\textbf{  Cond. No.          } &      1.00   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:            total_sales   R-squared (uncentered):                   0.346\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.345\n",
       "Method:                 Least Squares   F-statistic:                              762.3\n",
       "Date:                Tue, 18 Jun 2024   Prob (F-statistic):                   4.69e-135\n",
       "Time:                        00:01:32   Log-Likelihood:                         -2158.2\n",
       "No. Observations:                1443   AIC:                                      4318.\n",
       "Df Residuals:                    1442   BIC:                                      4324.\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "stsp_owners  2.913e-07   1.06e-08     27.609      0.000    2.71e-07    3.12e-07\n",
       "==============================================================================\n",
       "Omnibus:                     1648.013   Durbin-Watson:                   1.169\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           355577.245\n",
       "Skew:                           5.367   Prob(JB):                         0.00\n",
       "Kurtosis:                      79.149   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************** \n",
      " R-squared for Statsmodels OLS (train data): 0.34581754752274263\n",
      "************************************************** \n",
      " Adjusted R-squared for Statsmodels OLS (train data): 0.3453638842408583\n"
     ]
    }
   ],
   "source": [
    "## add prediction for sales\n",
    "\n",
    "## function for predicting sales\n",
    "\n",
    "def predictor_sales(model_ols, df_aim_sales):\n",
    "\n",
    "    df_aim_sales = df_aim_sales[[\"stsp_owners\"]]\n",
    "    ## df_aim_sales = df_aim_sales[[\"const\", \"stsp_owners\"]]\n",
    "    \n",
    "    ## prediction\n",
    "    y_sales = model_ols.predict(df_aim_sales)\n",
    "\n",
    "    if y_sales[0] < 0:\n",
    "        return [0]\n",
    "    else:\n",
    "        return y_sales*1000000\n",
    "\n",
    "## fit statistical model for sales based on rating, uscore and owners\n",
    "\n",
    "df_steamdb = pd.read_json(r'../../data/steamdb.json')\n",
    "df_game_data = pd.read_csv(r'../../data/game_data_all.csv')\n",
    "df_sales = pd.read_csv(r'../../data/vgchartz-2024.csv')\n",
    "\n",
    "from utilities import URLMerge\n",
    "\n",
    "df_merge_1 = URLMerge(df_steamdb, 'store_url', df_game_data, 'link')\n",
    "\n",
    "df_merge_1[\"title\"] = df_merge_1[\"name\"]\n",
    "\n",
    "df_merge_2 = pd.merge(df_sales, df_merge_1, on=\"title\", how=\"inner\")\n",
    "\n",
    "df_merge_2 = df_merge_2[[\"total_sales\", \"stsp_owners\"]]\n",
    "df_merge_2.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "display(df_merge_2.describe())\n",
    "\n",
    "model_ols = sm.OLS(df_merge_2[\"total_sales\"], df_merge_2.drop(\"total_sales\", axis=1)).fit()\n",
    "## model_ols = sm.OLS(df_merge_2[\"total_sales\"], sm.add_constant(df_merge_2.drop(\"total_sales\", axis=1))).fit()\n",
    "adj_r2_sm = model_ols.rsquared_adj\n",
    "display(model_ols.summary())\n",
    "print(\"*\"*50, \"\\n\", \"R-squared for Statsmodels OLS (train data):\", model_ols.rsquared)\n",
    "print(\"*\"*50, \"\\n\", \"Adjusted R-squared for Statsmodels OLS (train data):\", adj_r2_sm)\n",
    "\n",
    "\n",
    "## save model as pickle\n",
    "with gzip.open(\"../../models/final_model_sales.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump(model_ols, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
